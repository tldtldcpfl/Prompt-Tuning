# Prompt-Tuning
- Dialog system should continually learn new knowledge without forgetting old ones, and adapt to new domains.
- However, continual training methods easily leads to catastrophic forgetting problem.
- To avoid forgetting, model can learn only a few prompt tokens's embdeddings for each task while freezing the backbone pre-trained model.
  
